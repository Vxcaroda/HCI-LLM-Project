+-------------------------------------------+
| David Vicaro: The LLM I am using is GPT-4 |
+-------------------------------------------+

Q1) write a python program that does auto text completion. do not use any packages that do not work on windows, and make it run in terminal for simplicity

A1) Auto text completion can be a complex task, and building a sophisticated model from scratch is beyond the scope of this answer. However, I can provide 
    a simple example using a prefix tree (Trie) data structure to demonstrate the basic idea. A Trie is a tree-like data structure that stores a dynamic 
    set of strings, where each node in the tree represents a single character. This makes it a good fit for building a basic auto text completion system.
    Here's a simple Python program that demonstrates auto text completion using a Trie:

class TrieNode:
    def __init__(self):
        self.children = {}
        self.is_end_of_word = False

class Trie:
    def __init__(self):
        self.root = TrieNode()

    def insert(self, word):
        node = self.root
        for char in word:
            if char not in node.children:
                node.children[char] = TrieNode()
            node = node.children[char]
        node.is_end_of_word = True

    def search(self, prefix):
        node = self.root
        for char in prefix:
            if char not in node.children:
                return []
            node = node.children[char]
        return self._collect_all_words(node, prefix)

    def _collect_all_words(self, node, prefix):
        words = []
        if node.is_end_of_word:
            words.append(prefix)
        for char, child in node.children.items():
            words += self._collect_all_words(child, prefix + char)
        return words

def main():
    trie = Trie()
    words = ["apple", "app", "banana", "bat", "batman", "car", "carbon", "cargo"]
    for word in words:
        trie.insert(word)

    while True:
        prefix = input("Enter prefix: ")
        if prefix == "exit":
            break
        completions = trie.search(prefix)
        print("Completions:", completions)

if __name__ == "__main__":
    main()

    This program creates a simple Trie and inserts some example words. The user can then input a prefix, and the program will return a list of possible completions. 
    To exit the program, type "exit". Note that this example is case-sensitive and doesn't handle special characters or punctuation. You can customize the code to 
    improve its functionality and handle more complex scenarios.

Q2) where can I find a useful collection of words to use. in other words I want a large dictionary of words to use in this program

A2) A popular source for a large collection of words is the word list from the SCOWL (Spell Checker Oriented Word Lists) project, which is used by various open-source 
    spell checking libraries. The largest word list from this project is available for download from the following link:
    wordlist.7z (15.8 MB)
    After downloading the file, you will need to extract its content, which is a plain text file named wordlist.txt. Each line in the file represents a single word. 
    To load this list of words into your Python program, you can use the following function:

def load_words_from_file(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        words = [line.strip() for line in file]
    return words

To use this function in your main program, simply call it and pass the file path of your wordlist.txt file:

def main():
    trie = Trie()
    words = load_words_from_file("wordlist.txt")
    for word in words:
        trie.insert(word)

    while True:
        prefix = input("Enter prefix: ")
        if prefix == "exit":
            break
        completions = trie.search(prefix)
        print("Completions:", completions)

if __name__ == "__main__":
    main()

This will load the words from the file and insert them into your Trie, providing a much larger dictionary of words for your auto text completion program.

Q3) great. everything is working. next, write a python program that does auto word correction. do not use any packages that do not work on windows, 
    and make it run in terminal for simplicity. it should be a brand new file, not integrated in the last program. 

A2) Here's a simple Python program that demonstrates auto text correction using a Trie and the Levenshtein distance to find the best corrections:

class TrieNode:
    def __init__(self):
        self.children = {}
        self.is_end_of_word = False

class Trie:
    def __init__(self):
        self.root = TrieNode()

    def insert(self, word):
        node = self.root
        for char in word:
            if char not in node.children:
                node.children[char] = TrieNode()
            node = node.children[char]
        node.is_end_of_word = True

    def search(self, word, max_edit_distance=2):
        current_row = range(len(word) + 1)
        corrections = []

        for char, child in self.root.children.items():
            self._recursive_search(child, char, word, current_row, corrections, max_edit_distance)

        return corrections

    def _recursive_search(self, node, word_so_far, word, prev_row, corrections, max_edit_distance):
        columns = len(word) + 1
        current_row = [prev_row[0] + 1]

        for column in range(1, columns):
            insert_cost = current_row[-1] + 1
            delete_cost = prev_row[column] + 1
            replace_cost = prev_row[column - 1] + (word_so_far[-1] != word[column - 1])
            current_row.append(min(insert_cost, delete_cost, replace_cost))

        if current_row[-1] <= max_edit_distance and node.is_end_of_word:
            corrections.append((current_row[-1], word_so_far))

        if min(current_row) <= max_edit_distance:
            for letter, child in node.children.items():
                self._recursive_search(child, word_so_far + letter, word, current_row, corrections, max_edit_distance)

def load_words_from_file(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        words = [line.strip() for line in file]
    return words

def main():
    trie = Trie()
    words = load_words_from_file("HCI-LLM-Project\HCI_LLM\dictionary.txt")
    for word in words:
        trie.insert(word)

    while True:
        input_word = input("Enter a word: ")
        if input_word == "exit":
            break
        corrections = trie.search(input_word)
        if corrections:
            sorted_corrections = sorted(corrections, key=lambda x: (x[0], x[1]))
            print("Corrections:", [correction[1] for correction in sorted_corrections])
        else:
            print("No corrections found.")

if __name__ == "__main__":
    main()

!!!!At this point I realized that the task is to take in a sentence as an input and output the predicted next word in the sentence. so I will be trying to rewrite the 
text completion program to achieve this goal using my remaining 8 Questions. 

Q3) write a python program that takes a sentence as input, a string of words, and should predict the next word. do not use any packages that do not work on windows, 
and make it run in terminal for simplicity

A3) Creating a sophisticated word prediction model would typically require a large language model and a significant amount of training data, like GPT-based models. 
However, I can provide you with a simple program that uses n-grams and basic Python libraries. This program will be limited in its prediction capabilities and 
won't be as accurate as more advanced models.

Here's a Python script that takes a sentence as input and predicts the next word based on word frequency using bigrams (pairs of consecutive words):


import re
from collections import defaultdict, Counter

# Sample text for training the model
training_text = """
This is a sample training text. You can replace this text with a larger dataset for better results.
The more text you provide, the more accurate the predictions will be.
"""

def tokenize(text):
    words = re.findall(r'\b\w+\b', text.lower())
    return words

def train_bigrams(words):
    bigrams = defaultdict(Counter)
    for i in range(len(words) - 1):
        bigrams[words[i]][words[i + 1]] += 1
    return bigrams

def predict_next_word(bigrams, current_word):
    if not bigrams[current_word]:
        return None
    most_common_word = bigrams[current_word].most_common(1)[0][0]
    return most_common_word

def main():
    words = tokenize(training_text)
    bigrams = train_bigrams(words)

    input_sentence = input("Enter a sentence: ")
    input_words = tokenize(input_sentence)
    last_word = input_words[-1]

    next_word = predict_next_word(bigrams, last_word)
    if next_word:
        print("Predicted next word:", next_word)
    else:
        print("Sorry, unable to predict the next word.")

if __name__ == "__main__":
    main()

This script uses a small sample text for training, so the predictions may not be very accurate. You can replace the training_text variable with a larger 
dataset to improve prediction quality. To run the script, save it as a Python file (e.g., word_predictor.py) and execute it in the terminal with python word_predictor.py.

//So i downloaded a portion of text8, which is a A preprocessed and cleaned version of the first 100 MB of English Wikipedia text from kaggle.com and put it in a taxt file and used that to train the model. 
// I also grabbed news articles text from kaggle and used that as bonus training data.  

Q4) how do i make the program take in a txt file as the training text 
You can modify the program to accept a text file as input for the training text. Here's the updated version of the script that reads a text file and uses its content as the training text:

import re
from collections import defaultdict, Counter

def read_training_text(filename):
    with open(filename, 'r', encoding='utf-8') as file:
        return file.read()

def tokenize(text):
    words = re.findall(r'\b\w+\b', text.lower())
    return words

def train_bigrams(words):
    bigrams = defaultdict(Counter)
    for i in range(len(words) - 1):
        bigrams[words[i]][words[i + 1]] += 1
    return bigrams

def predict_next_word(bigrams, current_word):
    if not bigrams[current_word]:
        return None
    most_common_word = bigrams[current_word].most_common(1)[0][0]
    return most_common_word

def main():
    filename = input("Enter the training text filename: ")
    training_text = read_training_text(filename)

    words = tokenize(training_text)
    bigrams = train_bigrams(words)

    input_sentence = input("Enter a sentence: ")
    input_words = tokenize(input_sentence)
    last_word = input_words[-1]

    next_word = predict_next_word(bigrams, last_word)
    if next_word:
        print("Predicted next word:", next_word)
    else:
        print("Sorry, unable to predict the next word.")

if __name__ == "__main__":
    main()

Now, the program asks the user to input the filename of the training text. Make sure to specify the correct file path if the text file is located in a different directory.
The read_training_text function reads the content of the specified text file and returns it as a string. The rest of the script remains the same. Save the updated script 
as a Python file (e.g., word_predictor_file_input.py) and execute it in the terminal with python word_predictor_file_input.py.
Q5) it should just take a relative file path to the txt file training data
A5) You can simplify the script to accept a relative file path for the training text. In this case, the program won't ask the user for input, and you need to specify the file path directly in the code. Here's the updated version of the script:

python
Copy code
import re
from collections import defaultdict, Counter

# Specify the relative path to the training text file
training_text_file = 'your_training_text.txt'

def read_training_text(filename):
    with open(filename, 'r', encoding='utf-8') as file:
        return file.read()

def tokenize(text):
    words = re.findall(r'\b\w+\b', text.lower())
    return words

def train_bigrams(words):
    bigrams = defaultdict(Counter)
    for i in range(len(words) - 1):
        bigrams[words[i]][words[i + 1]] += 1
    return bigrams

def predict_next_word(bigrams, current_word):
    if not bigrams[current_word]:
        return None
    most_common_word = bigrams[current_word].most_common(1)[0][0]
    return most_common_word

def main():
    training_text = read_training_text(training_text_file)

    words = tokenize(training_text)
    bigrams = train_bigrams(words)

    input_sentence = input("Enter a sentence: ")
    input_words = tokenize(input_sentence)
    last_word = input_words[-1]

    next_word = predict_next_word(bigrams, last_word)
    if next_word:
        print("Predicted next word:", next_word)
    else:
        print("Sorry, unable to predict the next word.")

if __name__ == "__main__":
    main()

Replace 'your_training_text.txt' with the relative path to your training text file. Make sure the specified path is correct, or you'll encounter a file not found error.
 Save the updated script as a Python file (e.g., word_predictor_relative_path.py) and execute it in the terminal with python word_predictor_relative_path.py.

Q6) take my code and make it run in a loop so it keeps taking sentences until the user types 'exit'
    *** Then I pasted in the above code and it generated the following:

A6) Sure, here's the modified code that runs in a loop until the user types "exit":

import re
from collections import defaultdict, Counter

def read_training_text(filename):
    with open(filename, 'r', encoding='utf-8') as file:
        return file.read()

def tokenize(text):
    words = re.findall(r'\b\w+\b', text.lower())
    return words

def train_bigrams(words):
    bigrams = defaultdict(Counter)
    for i in range(len(words) - 1):
        bigrams[words[i]][words[i + 1]] += 1
    return bigrams

def predict_next_word(bigrams, current_word):
    if not bigrams[current_word]:
        return None
    most_common_word = bigrams[current_word].most_common(1)[0][0]
    return most_common_word

def main():
    filename = "HCI-LLM-Project\HCI_LLM/text8.txt"
    training_text = read_training_text(filename)

    words = tokenize(training_text)
    bigrams = train_bigrams(words)

    while True:
        input_sentence = input("Enter a sentence (type 'exit' to quit): ")
        if input_sentence.lower() == 'exit':
            break
        input_words = tokenize(input_sentence)
        last_word = input_words[-1]

        next_word = predict_next_word(bigrams, last_word)
        if next_word:
            print("Predicted next word:", next_word)
        else:
            print("Sorry, unable to predict the next word.")

if __name__ == "__main__":
    main()


This modified code uses a while loop to repeatedly prompt the user to enter a sentence until the user types "exit". Once the user enters a sentence, the code tokenizes 
the sentence and predicts the next word using the predict_next_word() function. The predicted next word is then printed to the console.